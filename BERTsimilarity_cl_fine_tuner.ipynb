{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTsim_cl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ed43154693b456b8239826a985adc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c1226a8ab7345ef94ace66f065b8eb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fbd021686b444298d2d05a1afe63b8f",
              "IPY_MODEL_57d45d56844a40058e57a80b492a9396"
            ]
          }
        },
        "1c1226a8ab7345ef94ace66f065b8eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fbd021686b444298d2d05a1afe63b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_551e91d83b714f8a9c780d04cdd0a0a9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90636cf01d5d4aa682a634b42a3a322f"
          }
        },
        "57d45d56844a40058e57a80b492a9396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_049da8cea8404e35b62655574a1b8d05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 216kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_582d016c9a1b4f4da45571e9050387e8"
          }
        },
        "551e91d83b714f8a9c780d04cdd0a0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90636cf01d5d4aa682a634b42a3a322f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "049da8cea8404e35b62655574a1b8d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "582d016c9a1b4f4da45571e9050387e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7ad0b474071481f92b55a444af60668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16dfd7c0f85f4e3ea225c584fa505224",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9320fb1100a34ebd88a638586d1d56f5",
              "IPY_MODEL_dae79b56919c43d1beed298212111d3a"
            ]
          }
        },
        "16dfd7c0f85f4e3ea225c584fa505224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9320fb1100a34ebd88a638586d1d56f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e285a529c4774bc8a7d7c3571d81b193",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57934b6d0e2e49379bf08298b5396b22"
          }
        },
        "dae79b56919c43d1beed298212111d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36139d37d1d44541930481728b12cf22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 34.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6beb05d364c04ad697ed60d720b1b3ee"
          }
        },
        "e285a529c4774bc8a7d7c3571d81b193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57934b6d0e2e49379bf08298b5396b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36139d37d1d44541930481728b12cf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6beb05d364c04ad697ed60d720b1b3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ce082c4da704faf8f64231094f423ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfd50b5a97f44720b5bea0c6a688c4d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c70929378785428f9e79c63271102601",
              "IPY_MODEL_29b3655dbdb845a0aab4b5aa92b2ee3a"
            ]
          }
        },
        "cfd50b5a97f44720b5bea0c6a688c4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c70929378785428f9e79c63271102601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_919dfd83da534896b6431fa1883099ac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5f9768c6d224897a40d9d3982696917"
          }
        },
        "29b3655dbdb845a0aab4b5aa92b2ee3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46c7aa7cff924e658ded5c1757873227",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c501a713229d4b5fbc98c827f027ee0c"
          }
        },
        "919dfd83da534896b6431fa1883099ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5f9768c6d224897a40d9d3982696917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46c7aa7cff924e658ded5c1757873227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c501a713229d4b5fbc98c827f027ee0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzC1mgRmWdK"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWmhlyh7DJK0"
      },
      "source": [
        "We need to install the transformers library first, if we use Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyOsBDdmpHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321838f6-c4e0-4ea2-ff97-9d6369962e9f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiuqmnMDTG3"
      },
      "source": [
        "From transformers, we need only the model itself, which is `DistilBertForSequenceClassification`; special optimizer that works with it, which is `AdamW`; and a pretrained tokenizer `DistilBertTokenizer` to feed our data correctly into the model. \n",
        "\n",
        "For the sake of saving space and performance, we use `DistilBert` in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI2RRh0anNai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288c7a3b-d4b4-4188-e559-30e29f5cd10c"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
        "from transformers import DistilBertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "!kaggle competitions download -c shopee-product-matching!"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7_o-eY4DyEd"
      },
      "source": [
        "# Downloading and unpacking the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox9JncIamvf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b931c287-4c5b-4647-9e1e-611fef177c71"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkLqTLmx5c0"
      },
      "source": [
        "titles = pd.read_csv(\"/content/drive/My Drive/NN/train.csv\")\n",
        "titles_only = titles[\"title\"]\n",
        "label_grps = titles[\"label_group\"] \n",
        "titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJemSPnmo6e"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "t1 = []\n",
        "t2 = []\n",
        "same = []\n",
        "c = 0\n",
        "for i in range(titles.shape[0]):\n",
        "  for j in range(titles.shape[0]):\n",
        "    t1.append(titles_only[i])\n",
        "    t2.append(titles_only[j])\n",
        "    t = label_grps[i]==label_grps[j]\n",
        "    c += t\n",
        "    same.append(t)\n",
        "  if i % 100 == 0:\n",
        "    print(i, c)\n",
        "  if c == 10000:\n",
        "    break\n",
        "df[\"t1\"] = t1\n",
        "df[\"t2\"] = t2\n",
        "df[\"same\"] = same\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMOISbQC1W-p"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"t1\"] = t1[:-1]\n",
        "df[\"t2\"] = t2[:-1]\n",
        "df[\"same\"] = same\n",
        "df.to_csv(\"/content/drive/My Drive/NN/trainform.csv\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jyWhowR77qo"
      },
      "source": [
        " df = pd.read_csv(\"/content/drive/My Drive/NN/trainform.csv\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF7McFixre3T"
      },
      "source": [
        "tr = df.loc[df[\"same\"] == True]\n",
        "tr\n",
        "fl = df.loc[df[\"same\"] == False].reset_index()\n",
        "fl\n",
        "perc = np.random.rand(fl.shape[0])\n",
        "perc = perc < (tr.shape[0]*5/fl.shape[0])\n",
        "fl = fl[perc]\n",
        "fl.to_csv(\"/content/drive/My Drive/NN/train_tr.csv\")\n",
        "tr.to_csv(\"/content/drive/My Drive/NN/train_fl.csv\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGAIzAi_1n4"
      },
      "source": [
        "tr = pd.read_csv(\"/content/drive/My Drive/NN/train_fl.csv\")\n",
        "fl = pd.read_csv(\"/content/drive/My Drive/NN/train_tr.csv\")\n",
        "perc = np.random.rand(fl.shape[0])\n",
        "perc = perc < (tr.shape[0]/fl.shape[0])\n",
        "fl = fl[perc]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "mxqdpCafABxg",
        "outputId": "91142c64-b815-48cc-e1d1-beb6d0689e70"
      },
      "source": [
        "fl"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "      <th>same</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19695</td>\n",
              "      <td>19696</td>\n",
              "      <td>19696</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>Sajadah Praktis Souvenir Siraman Unik Abu Dhab...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>23024</td>\n",
              "      <td>23025</td>\n",
              "      <td>23025</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>Overloose Basic Top Sourcesoriginal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>24168</td>\n",
              "      <td>24169</td>\n",
              "      <td>24169</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>(BISA COD) Paket Lengkap Filter Air Zernii Wat...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>33171</td>\n",
              "      <td>33173</td>\n",
              "      <td>33173</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>Bedong bayi instan katun halus praktis resleti...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>50399</td>\n",
              "      <td>50402</td>\n",
              "      <td>50402</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>DIGITAL WATCH NINOCS ( BERGARANSI )</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68258</th>\n",
              "      <td>77825815</td>\n",
              "      <td>77839370</td>\n",
              "      <td>77839370</td>\n",
              "      <td>RAK SUDUT Aluminium SA317 / RAK TOILET TEMPAT ...</td>\n",
              "      <td>GROSIR DRESS ANAK KAYSA - DASTER ARAB ANAK - F...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68259</th>\n",
              "      <td>77826089</td>\n",
              "      <td>77839645</td>\n",
              "      <td>77839645</td>\n",
              "      <td>RAK SUDUT Aluminium SA317 / RAK TOILET TEMPAT ...</td>\n",
              "      <td>ASAH PISAU SURMENE ASAHAN PISAU MURAH ASAHAN T...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68262</th>\n",
              "      <td>77827700</td>\n",
              "      <td>77841256</td>\n",
              "      <td>77841256</td>\n",
              "      <td>RAK SUDUT Aluminium SA317 / RAK TOILET TEMPAT ...</td>\n",
              "      <td>Pengaman laci lemari pintu perabotan dari bayi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68266</th>\n",
              "      <td>77831842</td>\n",
              "      <td>77845398</td>\n",
              "      <td>77845398</td>\n",
              "      <td>RAK SUDUT Aluminium SA317 / RAK TOILET TEMPAT ...</td>\n",
              "      <td>Mainan Puzzle Edukasi Anak</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68284</th>\n",
              "      <td>77852246</td>\n",
              "      <td>77865805</td>\n",
              "      <td>77865805</td>\n",
              "      <td>[IMPORT] - Pengait Bra Extension Penyambung ta...</td>\n",
              "      <td>Sandal Wanita Heels gliter pasir HT66</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13622 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...   same\n",
              "8           19695  ...  False\n",
              "13          23024  ...  False\n",
              "14          24168  ...  False\n",
              "21          33171  ...  False\n",
              "30          50399  ...  False\n",
              "...           ...  ...    ...\n",
              "68258    77825815  ...  False\n",
              "68259    77826089  ...  False\n",
              "68262    77827700  ...  False\n",
              "68266    77831842  ...  False\n",
              "68284    77852246  ...  False\n",
              "\n",
              "[13622 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9xqmeQyZRXh"
      },
      "source": [
        "dataa = {}\n",
        "#data = [fl,tr]\n",
        "labs = {}\n",
        "for i in [0,1]:\n",
        "  #p = data[i]\n",
        "  #perc = np.random.rand(p.shape[0])\n",
        "  #perc = perc > 0.8\n",
        "  #p[\"test\"] = perc\n",
        "  #dataa[i] = p\n",
        "  labs[i] = i"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYEcwVlHD2Jv"
      },
      "source": [
        "Initializig the tokenizer from the pretrained `distilbert-base-uncased` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EfPzA8Hm-0Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "6ed43154693b456b8239826a985adc70",
            "1c1226a8ab7345ef94ace66f065b8eb5",
            "0fbd021686b444298d2d05a1afe63b8f",
            "57d45d56844a40058e57a80b492a9396",
            "551e91d83b714f8a9c780d04cdd0a0a9",
            "90636cf01d5d4aa682a634b42a3a322f",
            "049da8cea8404e35b62655574a1b8d05",
            "582d016c9a1b4f4da45571e9050387e8",
            "d7ad0b474071481f92b55a444af60668",
            "16dfd7c0f85f4e3ea225c584fa505224",
            "9320fb1100a34ebd88a638586d1d56f5",
            "dae79b56919c43d1beed298212111d3a",
            "e285a529c4774bc8a7d7c3571d81b193",
            "57934b6d0e2e49379bf08298b5396b22",
            "36139d37d1d44541930481728b12cf22",
            "6beb05d364c04ad697ed60d720b1b3ee",
            "4ce082c4da704faf8f64231094f423ef",
            "cfd50b5a97f44720b5bea0c6a688c4d2",
            "c70929378785428f9e79c63271102601",
            "29b3655dbdb845a0aab4b5aa92b2ee3a",
            "919dfd83da534896b6431fa1883099ac",
            "d5f9768c6d224897a40d9d3982696917",
            "46c7aa7cff924e658ded5c1757873227",
            "c501a713229d4b5fbc98c827f027ee0c"
          ]
        },
        "outputId": "41156e69-8c3c-47c9-fc58-4ad8edbcdc44"
      },
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True, padding_side=\"right\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ed43154693b456b8239826a985adc70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7ad0b474071481f92b55a444af60668",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ce082c4da704faf8f64231094f423ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIK-URPGncKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d1be5d-1dc1-4155-f0b2-4984343d2d91"
      },
      "source": [
        "print(tokenizer.tokenize(\"This is the BERT tokenizer that we're going to use today.\"))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"This is the BERT tokenizer that we're going to use today.\")))\n",
        "tokenizer.encode_plus(\"This is the BERT tokenizer that we're going to use today.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'the', 'bert', 'token', '##izer', 'that', 'we', \"'\", 're', 'going', 'to', 'use', 'today', '.']\n",
            "[2023, 2003, 1996, 14324, 19204, 17629, 2008, 2057, 1005, 2128, 2183, 2000, 2224, 2651, 1012]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2023, 2003, 1996, 14324, 19204, 17629, 2008, 2057, 1005, 2128, 2183, 2000, 2224, 2651, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQiZKhtns-p"
      },
      "source": [
        "PAD = '[PAD]'\n",
        "PAD_ID = 0\n",
        "\n",
        "batch_size = 16\n",
        "validation_split = .3\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45zCLDbSEBh_"
      },
      "source": [
        "Here, we are going to re-use the `IMDBDataSet` class that we defined in the Lab 4. The only difference is that we get rid of pretrained word embeddings and replace a Spacy tokenizer with our pretrained `DistilBertTokenizer`.\n",
        "\n",
        "Remember, that in order to use BERT model, our sequence must have the `[CLS]` special token in the beginning and `[SEP]` in the end of the sequence. If we are using `DistilBertTokenizer.encode()` method, we can just specify `add_special_tokens=True` to not bother with it manually.\n",
        "\n",
        "Another important thing is that the pretrained `distilbert-base-uncased` model only accepts sequences of maximum length of 512 tokens. We set the `max_length` parameter to the `DistilBertTokenizer.encode()` method to trim them accordingly.\n",
        "\n",
        "Last modification that we make is adding `attention_masks`. This vector is basically telling the model which characters are meaningful and which one are used for padding. To do that, we put `1` in the position of meaningful tokens and `0` in the position of paddings.\n",
        "\n",
        "Since we already return torch tensors padded to have equal lengths in the Dataset, we don't need to define a custom `collate_fn` function as we did in the Lab 4. The default `collate_fn` function from `DataLoader` will handle the collating for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl11K6H4FmVT"
      },
      "source": [
        "Last modification that we make is adding `attention_masks`. This vector is basically telling the model which characters are meaningful and which one are used for padding. To do that, we put `1` in the position of meaningful tokens and `0` in the position of paddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1Dyq9NoOQq"
      },
      "source": [
        "class IMDBDataSet(Dataset):\n",
        "    def __init__(self, folders, pretrain_tokenizer, data, test=False):\n",
        "        self.tokenizer = pretrain_tokenizer\n",
        "        self.label_vocab = folders\n",
        "        self.max_len = 512\n",
        "        self.sign = False\n",
        "        self.in_data= data\n",
        "\n",
        "        if test:\n",
        "            self.sign = True\n",
        "        else:\n",
        "            self.sign = False\n",
        "            \n",
        "        self.data = []\n",
        "        \n",
        "        self.load()\n",
        "        \n",
        "    def load(self):\n",
        "        for label in self.label_vocab:\n",
        "          p = self.in_data[self.label_vocab[label]].dropna()\n",
        "          p = p.loc[p[\"test\"]==self.sign]\n",
        "          print(f'Reading {label} sentences...')\n",
        "          for t1,t2 in zip(p[\"t1\"],p[\"t2\"]):\n",
        "            text = self.tokenizer.encode(t1,t2, add_special_tokens = True, max_length=self.max_len, padding= \"max_length\", truncation = True, return_tensors = \"pt\")\n",
        "            attention_mask = text > 0\n",
        "            attention_mask = attention_mask.squeeze()\n",
        "            torch_label = torch.tensor(self.label_vocab[label], dtype = torch.long)\n",
        "              # append text, attention text and torch_label\n",
        "            self.data.append((text.squeeze(), attention_mask, torch_label))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx][0], self.data[idx][1], self.data[idx][2]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFM42wwFpCVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcda90e1-c2c2-40cf-c5d0-fdd735888b4a"
      },
      "source": [
        "train_data = IMDBDataSet(folders = labs,pretrain_tokenizer=tokenizer, data=dataa)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading 0 sentences...\n",
            "Reading 1 sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8h9KRWppIzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2db298-595d-41de-d64b-da5f1aa34296"
      },
      "source": [
        "test_data = IMDBDataSet(folders = labs,pretrain_tokenizer=tokenizer, data=dataa, test=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading 0 sentences...\n",
            "Reading 1 sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzmR3s2IpqqD"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqczduULq4OV"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_arcISsOzj"
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "validation_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Eae5oXsUak"
      },
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels= len(train_data.label_vocab), output_attentions = False, output_hidden_states=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGhKQ6jsswJA"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The DistilBERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gyvqU9s-ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "34109d5c-d495-4cde-aeec-a1ced1985e7b"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 1\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7a4d7588b2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Total number of training steps is number of batches * number of epochs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClW0hk8ZtgQ4"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBXToE2qrJWS"
      },
      "source": [
        "def multi_label_accuracy(preds, y):\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    confusion_vector = rounded_preds / y\n",
        "    \n",
        "    true_positives = torch.sum(confusion_vector == 1,dtype=torch.float)\n",
        "    false_positives = torch.sum(torch.isinf(confusion_vector),dtype=torch.float)\n",
        "    false_negatives = torch.sum(confusion_vector == 0 ,dtype=torch.float)\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector),dtype=torch.float)\n",
        "\n",
        "    accuracy = (true_positives+true_negatives) / (true_positives+true_negatives+false_negatives+false_positives)\n",
        "    precision = (true_positives) / (true_positives+false_positives)\n",
        "    recall = (true_positives) / (true_positives+false_negatives)\n",
        "    f_score = 2*(precision*recall)/(precision+recall)\n",
        "    return accuracy, precision, recall, f_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5G9QWPUtpcF"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfUd-Wr3t7rO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cddc27d-2548-4429-d62a-4efda35bc80a"
      },
      "source": [
        "# Taken from this tutorial: https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb\n",
        "# The code was modified\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())\n",
        "            \n",
        "            # Report progress.\n",
        "            print(f'  Batch {step:>5,}  of  {len(train_loader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, attention_mask= b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_loader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.4f}\")\n",
        "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_loader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "            outputs = model(b_input_ids, attention_mask= b_input_mask)\n",
        "\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to(\"cpu\").numpy()\n",
        "        #print(label_ids)\n",
        "        #print( np.argmax(logits, axis=1).flatten())\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.6f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of    949.    Elapsed: 0m 29s.\n",
            "  Batch    80  of    949.    Elapsed: 0m 59s.\n",
            "  Batch   120  of    949.    Elapsed: 1m 32s.\n",
            "  Batch   160  of    949.    Elapsed: 2m 4s.\n",
            "  Batch   200  of    949.    Elapsed: 2m 37s.\n",
            "  Batch   240  of    949.    Elapsed: 3m 9s.\n",
            "  Batch   280  of    949.    Elapsed: 3m 42s.\n",
            "  Batch   320  of    949.    Elapsed: 4m 14s.\n",
            "  Batch   360  of    949.    Elapsed: 4m 47s.\n",
            "  Batch   400  of    949.    Elapsed: 5m 19s.\n",
            "  Batch   440  of    949.    Elapsed: 5m 52s.\n",
            "  Batch   480  of    949.    Elapsed: 6m 24s.\n",
            "  Batch   520  of    949.    Elapsed: 6m 57s.\n",
            "  Batch   560  of    949.    Elapsed: 7m 29s.\n",
            "  Batch   600  of    949.    Elapsed: 8m 2s.\n",
            "  Batch   640  of    949.    Elapsed: 8m 34s.\n",
            "  Batch   680  of    949.    Elapsed: 9m 7s.\n",
            "  Batch   720  of    949.    Elapsed: 9m 39s.\n",
            "  Batch   760  of    949.    Elapsed: 10m 12s.\n",
            "  Batch   800  of    949.    Elapsed: 10m 44s.\n",
            "  Batch   840  of    949.    Elapsed: 11m 17s.\n",
            "  Batch   880  of    949.    Elapsed: 11m 49s.\n",
            "  Batch   920  of    949.    Elapsed: 12m 22s.\n",
            "\n",
            "  Average training loss: 0.1535\n",
            "  Training epcoh took: 12m 45s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.973649\n",
            "  Validation took: 2m 1s\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f33nbvQ1v2A6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27d01ea-35ba-44d3-eb5a-71dd7dbb05cb"
      },
      "source": [
        "print(\"\")\n",
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "test_loss, test_accuracy = 0, 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_loader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to(\"cpu\").numpy()\n",
        "    print(label_ids)\n",
        "    print( np.argmax(logits, axis=1).flatten())\n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "\n",
        "    # Track the number of batches\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Report the final accuracy for this test run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
        "print(\"  Testing took: {:}m {:}s\".format(*epoch_time(t0, time.time())))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Testing...\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1]\n",
            "[1 1 1 1 1 1]\n",
            "  Accuracy: 0.98\n",
            "  Testing took: 1m 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DGJ1RYTHKti"
      },
      "source": [
        "def predict_same(model, s1, s2, voc):\n",
        "    model.eval()\n",
        "    text = tokenizer.encode(s1,s2, add_special_tokens = True, max_length=512, padding= \"max_length\", truncation = True, return_tensors = \"pt\")\n",
        "    attention_mask = text > 0\n",
        "    attention_mask = attention_mask.squeeze().to(device)\n",
        "    text = text.to(device)\n",
        "    bind = (text, attention_mask)\n",
        "    #print(text, attention_mask)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(bind[0], bind[1])[0]\n",
        "    proba = outputs.detach().cpu().numpy()\n",
        "    prediction, indices = torch.topk(torch.sigmoid(outputs), 1)\n",
        "    indices = indices.detach().cpu().numpy()\n",
        "    mojis = [voc[pred]for pred in indices[0]]\n",
        "    return mojis, proba[0]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwT-dyajzZGv",
        "outputId": "589f5b81-0123-49ff-f4dc-378916faac7b"
      },
      "source": [
        "print(predict_same(model, \"Victoria secret underware\",\"Victoria secret watch\", labs))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([1], array([-2.611601 ,  3.3308225], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZbAmRZZvRdA"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/NN/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/NN/test.csv\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd-EiK7NvNVZ"
      },
      "source": [
        "post_ids = []\n",
        "matches = []\n",
        "buf = []\n",
        "for i in range(test.shape[0]):\n",
        "    post_ids.append(test.loc[i]['posting_id'])\n",
        "    buf = str(test.loc[i]['posting_id'])\n",
        "    for j in range(train.shape[0]):\n",
        "        res = predict_same(model, test.loc[i]['title'],train.loc[j]['title'], labs)[0][0]\n",
        "        if j % 10000 == 0:\n",
        "            print(j)\n",
        "        if res == 1:\n",
        "            buf +=  \" \" + str(train.loc[j]['posting_id'])\n",
        "        \n",
        "    matches.append(buf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x97VeIa2luz"
      },
      "source": [
        "sub = pd.DataFrame()\n",
        "sub[\"posting_id\"] = post_ids\n",
        "sub[\"matches\"] = matches\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiPRjiUT421s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f145c0-e54e-4fe5-cc17-f12f4e02d9c2"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/NN/model/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/NN/model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/NN/model/tokenizer_config.json',\n",
              " '/content/drive/My Drive/NN/model/special_tokens_map.json',\n",
              " '/content/drive/My Drive/NN/model/vocab.txt',\n",
              " '/content/drive/My Drive/NN/model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh7qN9t-6WIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929e31cf-c3dd-4f6c-db86-e3f5c19e0c36"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "output_dir = '/content/drive/My Drive/NN/model/'\n",
        "model = DistilBertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8NxSSfP6mrK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}